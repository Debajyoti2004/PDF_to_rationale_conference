{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\Papers\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_file_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\Papers-20250106T173630Z-001.zip\"\n",
    "extract_to_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\Papers\"\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)\n",
    "\n",
    "print(f\"Files extracted to {extract_to_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\References\n"
     ]
    }
   ],
   "source": [
    "zip_file_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\Reference-20250106T174608Z-001.zip\"\n",
    "extract_to_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\References\"\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)\n",
    "\n",
    "print(f\"Files extracted to {extract_to_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with open(pdf_file, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in range(len(reader.pages)):\n",
    "            text += reader.pages[page].extract_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "papers = []\n",
    "labels = []\n",
    "id = []\n",
    "conference = []\n",
    "reference_non_publishable_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\References\\Reference\\Non-Publishable\"\n",
    "reference_publishable_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\References\\Reference\\Publishable\"\n",
    "\n",
    "\n",
    "# Process Non-Publishable PDFs\n",
    "for root, dirs, files in os.walk(reference_non_publishable_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_file_path = os.path.join(root, file)\n",
    "            text = extract_text_from_pdf(pdf_file_path)\n",
    "            id.append(file)\n",
    "            papers.append(text)\n",
    "            labels.append(0)\n",
    "            conference.append('null')\n",
    "\n",
    "# Process Publishable PDFs\n",
    "for root, dirs, files in os.walk(reference_publishable_path):\n",
    "    for dir in dirs:\n",
    "        conference_root = os.path.join(root, dir)\n",
    "        for _, _, files in os.walk(conference_root):\n",
    "            for file in files:\n",
    "                if file.endswith('.pdf'):\n",
    "                    file_path = os.path.join(conference_root, file)\n",
    "                    text = extract_text_from_pdf(file_path)\n",
    "                    id.append(file)\n",
    "                    papers.append(text)\n",
    "                    labels.append(1)\n",
    "                    conference.append(dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PDF</th>\n",
       "      <th>Label</th>\n",
       "      <th>Conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R001.pdf</td>\n",
       "      <td>Transdimensional Properties of Graphite in Rel...</td>\n",
       "      <td>0</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R002.pdf</td>\n",
       "      <td>Synergistic Convergence of Photosynthetic Path...</td>\n",
       "      <td>0</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R003.pdf</td>\n",
       "      <td>Deciphering the Enigmatic Properties of Metals...</td>\n",
       "      <td>0</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R004.pdf</td>\n",
       "      <td>AI-Driven Personalization in Online Education\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R005.pdf</td>\n",
       "      <td>Analyzing Real-Time Group Coordination in\\nAug...</td>\n",
       "      <td>0</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                                PDF  Label  \\\n",
       "0  R001.pdf  Transdimensional Properties of Graphite in Rel...      0   \n",
       "1  R002.pdf  Synergistic Convergence of Photosynthetic Path...      0   \n",
       "2  R003.pdf  Deciphering the Enigmatic Properties of Metals...      0   \n",
       "3  R004.pdf  AI-Driven Personalization in Online Education\\...      0   \n",
       "4  R005.pdf  Analyzing Real-Time Group Coordination in\\nAug...      0   \n",
       "\n",
       "  Conference  \n",
       "0       null  \n",
       "1       null  \n",
       "2       null  \n",
       "3       null  \n",
       "4       null  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "pdf_dict = {'ID': id, 'PDF': papers, 'Label': labels, 'Conference': conference}\n",
    "pdf_df = pd.DataFrame(pdf_dict)\n",
    "\n",
    "# Display the DataFrame\n",
    "pdf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ID          15 non-null     object\n",
      " 1   PDF         15 non-null     object\n",
      " 2   Label       15 non-null     int64 \n",
      " 3   Conference  15 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 612.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "pdf_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\data.csv\"\n",
    "pdf_df.to_csv(csv_file_path,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PDF</th>\n",
       "      <th>Label</th>\n",
       "      <th>Conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R002.pdf</td>\n",
       "      <td>Synergistic Convergence of Photosynthetic Path...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R003.pdf</td>\n",
       "      <td>Deciphering the Enigmatic Properties of Metals...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R015.pdf</td>\n",
       "      <td>Examining the Convergence of Denoising Diffusi...</td>\n",
       "      <td>1</td>\n",
       "      <td>TMLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R006.pdf</td>\n",
       "      <td>Detailed Action Identification in Baseball Gam...</td>\n",
       "      <td>1</td>\n",
       "      <td>CVPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R014.pdf</td>\n",
       "      <td>Addressing Min-Max Challenges in Nonconvex-Non...</td>\n",
       "      <td>1</td>\n",
       "      <td>TMLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R004.pdf</td>\n",
       "      <td>AI-Driven Personalization in Online Education\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R008.pdf</td>\n",
       "      <td>Advanced techniques for through and contextual...</td>\n",
       "      <td>1</td>\n",
       "      <td>EMNLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R001.pdf</td>\n",
       "      <td>Transdimensional Properties of Graphite in Rel...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R010.pdf</td>\n",
       "      <td>Detecting Medication Usage in Parkinson’s Dise...</td>\n",
       "      <td>1</td>\n",
       "      <td>KDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R007.pdf</td>\n",
       "      <td>Advancements in 3D Food Modeling: A Review of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>CVPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>R012.pdf</td>\n",
       "      <td>Safe Predictors for Input-Output Specification...</td>\n",
       "      <td>1</td>\n",
       "      <td>NeurIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>R011.pdf</td>\n",
       "      <td>Addressing Popularity Bias with Popularity-Con...</td>\n",
       "      <td>1</td>\n",
       "      <td>KDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>R013.pdf</td>\n",
       "      <td>Generalization in ReLU Networks via Restricted...</td>\n",
       "      <td>1</td>\n",
       "      <td>NeurIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R009.pdf</td>\n",
       "      <td>The Importance of Written Explanations in\\nAgg...</td>\n",
       "      <td>1</td>\n",
       "      <td>EMNLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R005.pdf</td>\n",
       "      <td>Analyzing Real-Time Group Coordination in\\nAug...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                                PDF  Label  \\\n",
       "0   R002.pdf  Synergistic Convergence of Photosynthetic Path...      0   \n",
       "1   R003.pdf  Deciphering the Enigmatic Properties of Metals...      0   \n",
       "2   R015.pdf  Examining the Convergence of Denoising Diffusi...      1   \n",
       "3   R006.pdf  Detailed Action Identification in Baseball Gam...      1   \n",
       "4   R014.pdf  Addressing Min-Max Challenges in Nonconvex-Non...      1   \n",
       "5   R004.pdf  AI-Driven Personalization in Online Education\\...      0   \n",
       "6   R008.pdf  Advanced techniques for through and contextual...      1   \n",
       "7   R001.pdf  Transdimensional Properties of Graphite in Rel...      0   \n",
       "8   R010.pdf  Detecting Medication Usage in Parkinson’s Dise...      1   \n",
       "9   R007.pdf  Advancements in 3D Food Modeling: A Review of ...      1   \n",
       "10  R012.pdf  Safe Predictors for Input-Output Specification...      1   \n",
       "11  R011.pdf  Addressing Popularity Bias with Popularity-Con...      1   \n",
       "12  R013.pdf  Generalization in ReLU Networks via Restricted...      1   \n",
       "13  R009.pdf  The Importance of Written Explanations in\\nAgg...      1   \n",
       "14  R005.pdf  Analyzing Real-Time Group Coordination in\\nAug...      0   \n",
       "\n",
       "         Conference  \n",
       "0   Non Publishable  \n",
       "1   Non Publishable  \n",
       "2              TMLR  \n",
       "3              CVPR  \n",
       "4              TMLR  \n",
       "5   Non Publishable  \n",
       "6             EMNLP  \n",
       "7   Non Publishable  \n",
       "8               KDD  \n",
       "9              CVPR  \n",
       "10          NeurIPS  \n",
       "11              KDD  \n",
       "12          NeurIPS  \n",
       "13            EMNLP  \n",
       "14  Non Publishable  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.fillna('Non Publishable',inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PDF</th>\n",
       "      <th>Label</th>\n",
       "      <th>Conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R007.pdf</td>\n",
       "      <td>Advancements in 3D Food Modeling: A Review of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>CVPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R011.pdf</td>\n",
       "      <td>Addressing Popularity Bias with Popularity-Con...</td>\n",
       "      <td>1</td>\n",
       "      <td>KDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R002.pdf</td>\n",
       "      <td>Synergistic Convergence of Photosynthetic Path...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R009.pdf</td>\n",
       "      <td>The Importance of Written Explanations in\\nAgg...</td>\n",
       "      <td>1</td>\n",
       "      <td>EMNLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R004.pdf</td>\n",
       "      <td>AI-Driven Personalization in Online Education\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R010.pdf</td>\n",
       "      <td>Detecting Medication Usage in Parkinson’s Dise...</td>\n",
       "      <td>1</td>\n",
       "      <td>KDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R015.pdf</td>\n",
       "      <td>Examining the Convergence of Denoising Diffusi...</td>\n",
       "      <td>1</td>\n",
       "      <td>TMLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R003.pdf</td>\n",
       "      <td>Deciphering the Enigmatic Properties of Metals...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R005.pdf</td>\n",
       "      <td>Analyzing Real-Time Group Coordination in\\nAug...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R014.pdf</td>\n",
       "      <td>Addressing Min-Max Challenges in Nonconvex-Non...</td>\n",
       "      <td>1</td>\n",
       "      <td>TMLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>R001.pdf</td>\n",
       "      <td>Transdimensional Properties of Graphite in Rel...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>R012.pdf</td>\n",
       "      <td>Safe Predictors for Input-Output Specification...</td>\n",
       "      <td>1</td>\n",
       "      <td>NeurIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>R013.pdf</td>\n",
       "      <td>Generalization in ReLU Networks via Restricted...</td>\n",
       "      <td>1</td>\n",
       "      <td>NeurIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R006.pdf</td>\n",
       "      <td>Detailed Action Identification in Baseball Gam...</td>\n",
       "      <td>1</td>\n",
       "      <td>CVPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R008.pdf</td>\n",
       "      <td>Advanced techniques for through and contextual...</td>\n",
       "      <td>1</td>\n",
       "      <td>EMNLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                                PDF  Label  \\\n",
       "0   R007.pdf  Advancements in 3D Food Modeling: A Review of ...      1   \n",
       "1   R011.pdf  Addressing Popularity Bias with Popularity-Con...      1   \n",
       "2   R002.pdf  Synergistic Convergence of Photosynthetic Path...      0   \n",
       "3   R009.pdf  The Importance of Written Explanations in\\nAgg...      1   \n",
       "4   R004.pdf  AI-Driven Personalization in Online Education\\...      0   \n",
       "5   R010.pdf  Detecting Medication Usage in Parkinson’s Dise...      1   \n",
       "6   R015.pdf  Examining the Convergence of Denoising Diffusi...      1   \n",
       "7   R003.pdf  Deciphering the Enigmatic Properties of Metals...      0   \n",
       "8   R005.pdf  Analyzing Real-Time Group Coordination in\\nAug...      0   \n",
       "9   R014.pdf  Addressing Min-Max Challenges in Nonconvex-Non...      1   \n",
       "10  R001.pdf  Transdimensional Properties of Graphite in Rel...      0   \n",
       "11  R012.pdf  Safe Predictors for Input-Output Specification...      1   \n",
       "12  R013.pdf  Generalization in ReLU Networks via Restricted...      1   \n",
       "13  R006.pdf  Detailed Action Identification in Baseball Gam...      1   \n",
       "14  R008.pdf  Advanced techniques for through and contextual...      1   \n",
       "\n",
       "         Conference  \n",
       "0              CVPR  \n",
       "1               KDD  \n",
       "2   Non Publishable  \n",
       "3             EMNLP  \n",
       "4   Non Publishable  \n",
       "5               KDD  \n",
       "6              TMLR  \n",
       "7   Non Publishable  \n",
       "8   Non Publishable  \n",
       "9              TMLR  \n",
       "10  Non Publishable  \n",
       "11          NeurIPS  \n",
       "12          NeurIPS  \n",
       "13             CVPR  \n",
       "14            EMNLP  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1, random_state=42).reset_index(drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv_file_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\project task-1\\data\\main_csv_data.csv\"\n",
    "df.to_csv(new_csv_file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PDF</th>\n",
       "      <th>Label</th>\n",
       "      <th>Conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R007.pdf</td>\n",
       "      <td>Advancements in 3D Food Modeling: A Review of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>CVPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R011.pdf</td>\n",
       "      <td>Addressing Popularity Bias with Popularity-Con...</td>\n",
       "      <td>1</td>\n",
       "      <td>KDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R002.pdf</td>\n",
       "      <td>Synergistic Convergence of Photosynthetic Path...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R009.pdf</td>\n",
       "      <td>The Importance of Written Explanations in\\nAgg...</td>\n",
       "      <td>1</td>\n",
       "      <td>EMNLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R004.pdf</td>\n",
       "      <td>AI-Driven Personalization in Online Education\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R010.pdf</td>\n",
       "      <td>Detecting Medication Usage in Parkinson’s Dise...</td>\n",
       "      <td>1</td>\n",
       "      <td>KDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R015.pdf</td>\n",
       "      <td>Examining the Convergence of Denoising Diffusi...</td>\n",
       "      <td>1</td>\n",
       "      <td>TMLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R003.pdf</td>\n",
       "      <td>Deciphering the Enigmatic Properties of Metals...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R005.pdf</td>\n",
       "      <td>Analyzing Real-Time Group Coordination in\\nAug...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R014.pdf</td>\n",
       "      <td>Addressing Min-Max Challenges in Nonconvex-Non...</td>\n",
       "      <td>1</td>\n",
       "      <td>TMLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>R001.pdf</td>\n",
       "      <td>Transdimensional Properties of Graphite in Rel...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non Publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>R012.pdf</td>\n",
       "      <td>Safe Predictors for Input-Output Specification...</td>\n",
       "      <td>1</td>\n",
       "      <td>NeurIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>R013.pdf</td>\n",
       "      <td>Generalization in ReLU Networks via Restricted...</td>\n",
       "      <td>1</td>\n",
       "      <td>NeurIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R006.pdf</td>\n",
       "      <td>Detailed Action Identification in Baseball Gam...</td>\n",
       "      <td>1</td>\n",
       "      <td>CVPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R008.pdf</td>\n",
       "      <td>Advanced techniques for through and contextual...</td>\n",
       "      <td>1</td>\n",
       "      <td>EMNLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                                PDF  Label  \\\n",
       "0   R007.pdf  Advancements in 3D Food Modeling: A Review of ...      1   \n",
       "1   R011.pdf  Addressing Popularity Bias with Popularity-Con...      1   \n",
       "2   R002.pdf  Synergistic Convergence of Photosynthetic Path...      0   \n",
       "3   R009.pdf  The Importance of Written Explanations in\\nAgg...      1   \n",
       "4   R004.pdf  AI-Driven Personalization in Online Education\\...      0   \n",
       "5   R010.pdf  Detecting Medication Usage in Parkinson’s Dise...      1   \n",
       "6   R015.pdf  Examining the Convergence of Denoising Diffusi...      1   \n",
       "7   R003.pdf  Deciphering the Enigmatic Properties of Metals...      0   \n",
       "8   R005.pdf  Analyzing Real-Time Group Coordination in\\nAug...      0   \n",
       "9   R014.pdf  Addressing Min-Max Challenges in Nonconvex-Non...      1   \n",
       "10  R001.pdf  Transdimensional Properties of Graphite in Rel...      0   \n",
       "11  R012.pdf  Safe Predictors for Input-Output Specification...      1   \n",
       "12  R013.pdf  Generalization in ReLU Networks via Restricted...      1   \n",
       "13  R006.pdf  Detailed Action Identification in Baseball Gam...      1   \n",
       "14  R008.pdf  Advanced techniques for through and contextual...      1   \n",
       "\n",
       "         Conference  \n",
       "0              CVPR  \n",
       "1               KDD  \n",
       "2   Non Publishable  \n",
       "3             EMNLP  \n",
       "4   Non Publishable  \n",
       "5               KDD  \n",
       "6              TMLR  \n",
       "7   Non Publishable  \n",
       "8   Non Publishable  \n",
       "9              TMLR  \n",
       "10  Non Publishable  \n",
       "11          NeurIPS  \n",
       "12          NeurIPS  \n",
       "13             CVPR  \n",
       "14            EMNLP  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Valid article: Advancements in 3D Food Modeling: A Review of the\n",
      "MetaFood Challenge Techniques and Outcomes\n",
      "Abstract\n",
      "The growing focus on leveraging computer vision for dietary oversight and nutri-\n",
      "tion tracking has spurred the creation of sophisticated 3D reconstruction methods\n",
      "for food. The lack of comprehensive, high-fidelity data, coupled with limited\n",
      "collaborative efforts between academic and industrial sectors, has significantly\n",
      "hindered advancements in this domain. This study addresses these obstacles by\n",
      "introducing the MetaFood Challenge, aimed at generating precise, volumetrically\n",
      "accurate 3D food models from 2D images, utilizing a checkerboard for size cal-\n",
      "ibration. The challenge was structured around 20 food items across three levels\n",
      "of complexity: easy (200 images), medium (30 images), and hard (1 image). A\n",
      "total of 16 teams participated in the final assessment phase. The methodologies\n",
      "developed during this challenge have yielded highly encouraging outcomes in\n",
      "3D food reconstruction, showing great promise for refining portion estimation in\n",
      "dietary evaluations and nutritional tracking. Further information on this workshop\n",
      "challenge and the dataset is accessible via the provided URL.\n",
      "1 Introduction\n",
      "The convergence of computer vision technologies with culinary practices has pioneered innovative\n",
      "approaches to dietary monitoring and nutritional assessment. The MetaFood Workshop Challenge\n",
      "represents a landmark initiative in this emerging field, responding to the pressing demand for precise\n",
      "and scalable techniques for estimating food portions and monitoring nutritional consumption. Such\n",
      "technologies are vital for fostering healthier eating behaviors and addressing health issues linked to\n",
      "diet.\n",
      "By concentrating on the development of accurate 3D models of food derived from various visual\n",
      "inputs, including multiple views and single perspectives, this challenge endeavors to bridge the\n",
      "disparity between current methodologies and practical needs. It promotes the creation of unique\n",
      "solutions capable of managing the intricacies of food morphology, texture, and illumination, while also\n",
      "meeting the real-world demands of dietary evaluation. This initiative gathers experts from computer\n",
      "vision, machine learning, and nutrition science to propel 3D food reconstruction technologies forward.\n",
      "These advancements have the potential to substantially enhance the precision and utility of food\n",
      "portion estimation across diverse applications, from individual health tracking to extensive nutritional\n",
      "investigations.\n",
      "Conventional methods for assessing diet, like 24-Hour Recall or Food Frequency Questionnaires\n",
      "(FFQs), are frequently reliant on manual data entry, which is prone to inaccuracies and can be\n",
      "burdensome. The lack of 3D data in 2D RGB food images further complicates the use of regression-\n",
      "based methods for estimating food portions directly from images of eating occasions. By enhancing\n",
      "3D reconstruction for food, the aim is to provide more accurate and intuitive nutritional assessment\n",
      "tools. This technology could revolutionize the sharing of culinary experiences and significantly\n",
      "impact nutrition science and public health.\n",
      "Participants were tasked with creating 3D models of 20 distinct food items from 2D images, mim-\n",
      "icking scenarios where mobile devices equipped with depth-sensing cameras are used for dietary\n",
      ".recording and nutritional tracking. The challenge was segmented into three tiers of difficulty based\n",
      "on the number of images provided: approximately 200 images for easy, 30 for medium, and a single\n",
      "top-view image for hard. This design aimed to rigorously test the adaptability and resilience of\n",
      "proposed solutions under various realistic conditions. A notable feature of this challenge was the use\n",
      "of a visible checkerboard for physical referencing and the provision of depth images for each frame,\n",
      "ensuring the 3D models maintained accurate real-world measurements for portion size estimation.\n",
      "This initiative not only expands the frontiers of 3D reconstruction technology but also sets the stage\n",
      "for more reliable and user-friendly real-world applications, including image-based dietary assessment.\n",
      "The resulting solutions hold the potential to profoundly influence nutritional intake monitoring and\n",
      "comprehension, supporting broader health and wellness objectives. As progress continues, innovative\n",
      "applications are anticipated to transform personal health management, nutritional research, and the\n",
      "wider food industry. The remainder of this report is structured as follows: Section 2 delves into the\n",
      "existing literature on food portion size estimation, Section 3 describes the dataset and evaluation\n",
      "framework used in the challenge, and Sections 4, 5, and 6 discuss the methodologies and findings of\n",
      "the top three teams (V olETA, ININ-VIAUN, and FoodRiddle), respectively.\n",
      "2 Related Work\n",
      "Estimating food portions is a crucial part of image-based dietary assessment, aiming to determine the\n",
      "volume, energy content, or macronutrients directly from images of meals. Unlike the well-studied\n",
      "task of food recognition, estimating food portions is particularly challenging due to the lack of 3D\n",
      "information and physical size references necessary for accurately judging the actual size of food\n",
      "portions. Accurate portion size estimation requires understanding the volume and density of food,\n",
      "elements that are hard to deduce from a 2D image, underscoring the need for sophisticated techniques\n",
      "to tackle this problem. Current methods for estimating food portions are grouped into four categories.\n",
      "Stereo-Based Approaches use multiple images to reconstruct the 3D structure of food. Some methods\n",
      "estimate food volume using multi-view stereo reconstruction based on epipolar geometry, while\n",
      "others perform two-view dense reconstruction. Simultaneous Localization and Mapping (SLAM) has\n",
      "also been used for continuous, real-time food volume estimation. However, these methods are limited\n",
      "by their need for multiple images, which is not always practical.\n",
      "Model-Based Approaches use predefined shapes and templates to estimate volume. For instance,\n",
      "certain templates are assigned to foods from a library and transformed based on physical references to\n",
      "estimate the size and location of the food. Template matching approaches estimate food volume from\n",
      "a single image, but they struggle with variations in food shapes that differ from predefined templates.\n",
      "Recent work has used 3D food meshes as templates to align camera and object poses for portion size\n",
      "estimation.\n",
      "Depth Camera-Based Approaches use depth cameras to create depth maps, capturing the distance from\n",
      "the camera to the food. These depth maps form a voxel representation used for volume estimation.\n",
      "The main drawback is the need for high-quality depth maps and the extra processing required for\n",
      "consumer-grade depth sensors.\n",
      "Deep Learning Approaches utilize neural networks trained on large image datasets for portion\n",
      "estimation. Regression networks estimate the energy value of food from single images or from an\n",
      "\"Energy Distribution Map\" that maps input images to energy distributions. Some networks use both\n",
      "images and depth maps to estimate energy, mass, and macronutrient content. However, deep learning\n",
      "methods require extensive data for training and are not always interpretable, with performance\n",
      "degrading when test images significantly differ from training data.\n",
      "While these methods have advanced food portion estimation, they face limitations that hinder their\n",
      "widespread use and accuracy. Stereo-based methods are impractical for single images, model-based\n",
      "approaches struggle with diverse food shapes, depth camera methods need specialized hardware,\n",
      "and deep learning approaches lack interpretability and struggle with out-of-distribution samples. 3D\n",
      "reconstruction offers a promising solution by providing comprehensive spatial information, adapting\n",
      "to various shapes, potentially working with single images, offering visually interpretable results,\n",
      "and enabling a standardized approach to food portion estimation. These benefits motivated the\n",
      "organization of the 3D Food Reconstruction challenge, aiming to overcome existing limitations and\n",
      "2develop more accurate, user-friendly, and widely applicable food portion estimation techniques,\n",
      "impacting nutritional assessment and dietary monitoring.\n",
      "3 Datasets and Evaluation Pipeline\n",
      "3.1 Dataset Description\n",
      "The dataset for the MetaFood Challenge features 20 carefully chosen food items from the MetaFood3D\n",
      "dataset, each scanned in 3D and accompanied by video recordings. To ensure precise size accuracy\n",
      "in the reconstructed 3D models, each food item was captured alongside a checkerboard and pattern\n",
      "mat, serving as physical scaling references. The challenge is divided into three levels of difficulty,\n",
      "determined by the quantity of 2D images provided for reconstruction:\n",
      "• Easy: Around 200 images taken from video.\n",
      "• Medium: 30 images.\n",
      "• Hard: A single image from a top-down perspective.\n",
      "Table 1 details the food items included in the dataset.\n",
      "Table 1: MetaFood Challenge Data Details\n",
      "Object Index Food Item Difficulty Level Number of Frames\n",
      "1 Strawberry Easy 199\n",
      "2 Cinnamon bun Easy 200\n",
      "3 Pork rib Easy 200\n",
      "4 Corn Easy 200\n",
      "5 French toast Easy 200\n",
      "6 Sandwich Easy 200\n",
      "7 Burger Easy 200\n",
      "8 Cake Easy 200\n",
      "9 Blueberry muffin Medium 30\n",
      "10 Banana Medium 30\n",
      "11 Salmon Medium 30\n",
      "12 Steak Medium 30\n",
      "13 Burrito Medium 30\n",
      "14 Hotdog Medium 30\n",
      "15 Chicken nugget Medium 30\n",
      "16 Everything bagel Hard 1\n",
      "17 Croissant Hard 1\n",
      "18 Shrimp Hard 1\n",
      "19 Waffle Hard 1\n",
      "20 Pizza Hard 1\n",
      "3.2 Evaluation Pipeline\n",
      "The evaluation process is split into two phases, focusing on the accuracy of the reconstructed 3D\n",
      "models in terms of shape (3D structure) and portion size (volume).\n",
      "3.2.1 Phase-I: Volume Accuracy\n",
      "In the first phase, the Mean Absolute Percentage Error (MAPE) is used to evaluate portion size\n",
      "accuracy, calculated as follows:\n",
      "MAPE =1\n",
      "nnX\n",
      "i=1\f\f\f\fAi−Fi\n",
      "Ai\f\f\f\f×100% (1)\n",
      "3where Aiis the actual volume (in ml) of the i-th food item obtained from the scanned 3D food mesh,\n",
      "andFiis the volume calculated from the reconstructed 3D mesh.\n",
      "3.2.2 Phase-II: Shape Accuracy\n",
      "Teams that perform well in Phase-I are asked to submit complete 3D mesh files for each food item.\n",
      "This phase involves several steps to ensure precision and fairness:\n",
      "•Model Verification: Submitted models are checked against the final Phase-I submissions for\n",
      "consistency, and visual inspections are conducted to prevent rule violations.\n",
      "•Model Alignment: Participants receive ground truth 3D models and a script to compute the\n",
      "final Chamfer distance. They must align their models with the ground truth and prepare a\n",
      "transformation matrix for each submitted object. The final Chamfer distance is calculated\n",
      "using these models and matrices.\n",
      "•Chamfer Distance Calculation: Shape accuracy is assessed using the Chamfer distance\n",
      "metric. Given two point sets XandY, the Chamfer distance is defined as:\n",
      "dCD(X, Y ) =1\n",
      "|X|X\n",
      "x∈Xmin\n",
      "y∈Y∥x−y∥2\n",
      "2+1\n",
      "|Y|X\n",
      "y∈Ymin\n",
      "x∈X∥x−y∥2\n",
      "2 (2)\n",
      "This metric offers a comprehensive measure of similarity between the reconstructed 3D models and\n",
      "the ground truth. The final ranking is determined by combining scores from both Phase-I (volume\n",
      "accuracy) and Phase-II (shape accuracy). Note that after the Phase-I evaluation, quality issues were\n",
      "found with the data for object 12 (steak) and object 15 (chicken nugget), so these items were excluded\n",
      "from the final overall evaluation.\n",
      "4 First Place Team - VolETA\n",
      "4.1 Methodology\n",
      "The team’s research employs multi-view reconstruction to generate detailed food meshes and calculate\n",
      "precise food volumes.\n",
      "4.1.1 Overview\n",
      "The team’s method integrates computer vision and deep learning to accurately estimate food volume\n",
      "from RGBD images and masks. Keyframe selection ensures data quality, supported by perceptual\n",
      "hashing and blur detection. Camera pose estimation and object segmentation pave the way for neural\n",
      "surface reconstruction, creating detailed meshes for volume estimation. Refinement steps, including\n",
      "isolated piece removal and scaling factor adjustments, enhance accuracy. This approach provides a\n",
      "thorough solution for accurate food volume assessment, with potential uses in nutrition analysis.\n",
      "4.1.2 The Team’s Proposal: VolETA\n",
      "The team starts by acquiring input data, specifically RGBD images and corresponding food object\n",
      "masks. The RGBD images, denoted as ID={IDi}n\n",
      "i=1, where nis the total number of frames,\n",
      "provide depth information alongside RGB images. The food object masks, {Mf\n",
      "i}n\n",
      "i=1, help identify\n",
      "regions of interest within these images.\n",
      "Next, the team selects keyframes. From the set {IDi}n\n",
      "i=1, keyframes {IK\n",
      "j}k\n",
      "j=1⊆ {IDi}n\n",
      "i=1are\n",
      "chosen. A method is implemented to detect and remove duplicate and blurry images, ensuring\n",
      "high-quality frames. This involves applying a Gaussian blurring kernel followed by the fast Fourier\n",
      "transform method. Near-Image Similarity uses perceptual hashing and Hamming distance threshold-\n",
      "ing to detect similar images and retain overlapping ones. Duplicates and blurry images are excluded\n",
      "to maintain data integrity and accuracy.\n",
      "Using the selected keyframes {IK\n",
      "j}k\n",
      "j=1, the team estimates camera poses through a method called\n",
      "PixSfM, which involves extracting features using SuperPoint, matching them with SuperGlue, and\n",
      "refining them. The outputs are the camera poses {Cj}k\n",
      "j=1, crucial for understanding the scene’s\n",
      "spatial layout.\n",
      "4In parallel, the team uses a tool called SAM for reference object segmentation. SAM segments\n",
      "the reference object with a user-provided prompt, producing a reference object mask MRfor each\n",
      "keyframe. This mask helps track the reference object across all frames. The XMem++ method\n",
      "extends the reference object mask MRto all frames, creating a comprehensive set of reference object\n",
      "masks {MR\n",
      "i}n\n",
      "i=1. This ensures consistent reference object identification throughout the dataset.\n",
      "To create RGBA images, the team combines RGB images, reference object masks {MR\n",
      "i}n\n",
      "i=1, and\n",
      "food object masks {MF\n",
      "i}n\n",
      "i=1. This step, denoted as {IR\n",
      "i}n\n",
      "i=1, integrates various data sources into a\n",
      "unified format for further processing.\n",
      "The team converts the RGBA images {IR\n",
      "i}n\n",
      "i=1and camera poses {Cj}k\n",
      "j=1into meaningful metadata\n",
      "and modeled data Dm. This transformation facilitates accurate scene reconstruction.\n",
      "The modeled data Dmis input into NeuS2 for mesh reconstruction. NeuS2 generates colorful meshes\n",
      "{Rf, Rr}for the reference and food objects, providing detailed 3D representations. The team uses the\n",
      "\"Remove Isolated Pieces\" technique to refine the meshes. Given that the scenes contain only one food\n",
      "item, the diameter threshold is set to 5% of the mesh size. This method deletes isolated connected\n",
      "components with diameters less than or equal to 5%, resulting in a cleaned mesh {RCf, RCr}. This\n",
      "step ensures that only significant parts of the mesh are retained.\n",
      "The team manually identifies an initial scaling factor Susing the reference mesh via MeshLab. This\n",
      "factor is fine-tuned to Sfusing depth information and food and reference masks, ensuring accurate\n",
      "scaling relative to real-world dimensions. Finally, the fine-tuned scaling factor Sfis applied to the\n",
      "cleaned food mesh RCf, producing the final scaled food mesh RFf. This step culminates in an\n",
      "accurately scaled 3D representation of the food object, enabling precise volume estimation.\n",
      "4.1.3 Detecting the scaling factor\n",
      "Generally, 3D reconstruction methods produce unitless meshes by default. To address this, the team\n",
      "manually determines the scaling factor by measuring the distance for each block of the reference\n",
      "object mesh. The average of all block lengths lavgis calculated, while the actual real-world length is\n",
      "constant at lreal= 0.012meters. The scaling factor S=lreal/lavgis applied to the clean food mesh\n",
      "RCf, resulting in the final scaled food mesh RFfin meters.\n",
      "The team uses depth information along with food and reference object masks to validate the scaling\n",
      "factors. The method for assessing food size involves using overhead RGB images for each scene.\n",
      "Initially, the pixel-per-unit (PPU) ratio (in meters) is determined using the reference object. Subse-\n",
      "quently, the food width ( fw) and length ( fl) are extracted using a food object mask. To determine the\n",
      "food height ( fh), a two-step process is followed. First, binary image segmentation is performed using\n",
      "the overhead depth and reference images, yielding a segmented depth image for the reference object.\n",
      "The average depth is then calculated using the segmented reference object depth ( dr). Similarly,\n",
      "employing binary image segmentation with an overhead food object mask and depth image, the\n",
      "average depth for the segmented food depth image ( df) is computed. The estimated food height fhis\n",
      "the absolute difference between dranddf. To assess the accuracy of the scaling factor S, the food\n",
      "bounding box volume (fw×fl×fh)×PPU is computed. The team evaluates if the scaling factor\n",
      "Sgenerates a food volume close to this potential volume, resulting in Sfine. Table 2 lists the scaling\n",
      "factors, PPU, 2D reference object dimensions, 3D food object dimensions, and potential volume.\n",
      "For one-shot 3D reconstruction, the team uses One-2-3-45 to reconstruct a 3D model from a single\n",
      "RGBA view input after applying binary image segmentation to both food RGB and mask images.\n",
      "Isolated pieces are removed from the generated mesh, and the scaling factor S, which is closer to the\n",
      "potential volume of the clean mesh, is reused.\n",
      "4.2 Experimental Results\n",
      "4.2.1 Implementation settings\n",
      "Experiments were conducted using two GPUs: GeForce GTX 1080 Ti/12G and RTX 3060/6G. The\n",
      "Hamming distance for near image similarity was set to 12. For Gaussian kernel radius, even numbers\n",
      "in the range [0...30] were used for detecting blurry images. The diameter for removing isolated pieces\n",
      "was set to 5%. NeuS2 was run for 15,000 iterations with a mesh resolution of 512x512, a unit cube\n",
      "\"aabb scale\" of 1, \"scale\" of 0.15, and \"offset\" of [0.5, 0.5, 0.5] for each food scene.\n",
      "54.2.2 VolETA Results\n",
      "The team extensively validated their approach on the challenge dataset and compared their results\n",
      "with ground truth meshes using MAPE and Chamfer distance metrics. The team’s approach was\n",
      "applied separately to each food scene. A one-shot food volume estimation approach was used if\n",
      "the number of keyframes kequaled 1; otherwise, a few-shot food volume estimation was applied.\n",
      "Notably, the keyframe selection process chose 34.8% of the total frames for the rest of the pipeline,\n",
      "showing the minimum frames with the highest information.\n",
      "Table 2: List of Extracted Information Using RGBD and Masks\n",
      "Level Id Label Sf PPU Rw×Rl (fw×fl×fh)\n",
      "1 Strawberry 0.08955223881 0.01786 320×360 (238 ×257×2.353)\n",
      "2 Cinnamon bun 0.1043478261 0.02347 236×274 (363 ×419×2.353)\n",
      "3 Pork rib 0.1043478261 0.02381 246×270 (435 ×778×1.176)\n",
      "Easy 4 Corn 0.08823529412 0.01897 291×339 (262 ×976×2.353)\n",
      "5 French toast 0.1034482759 0.02202 266×292 (530 ×581×2.53)\n",
      "6 Sandwich 0.1276595745 0.02426 230×265 (294 ×431×2.353)\n",
      "7 Burger 0.1043478261 0.02435 208×264 (378 ×400×2.353)\n",
      "8 Cake 0.1276595745 0.02143 256×300 (298 ×310×4.706)\n",
      "9 Blueberry muffin 0.08759124088 0.01801 291×357 (441 ×443×2.353)\n",
      "10 Banana 0.08759124088 0.01705 315×377 (446 ×857×1.176)\n",
      "Medium 11 Salmon 0.1043478261 0.02390 242×269 (201 ×303×1.176)\n",
      "13 Burrito 0.1034482759 0.02372 244×271 (251 ×917×2.353)\n",
      "14 Frankfurt sandwich 0.1034482759 0.02115 266×304 (400 ×1022×2.353)\n",
      "16 Everything bagel 0.08759124088 0.01747 306×368 (458 ×134×1.176)\n",
      "Hard 17 Croissant 0.1276595745 0.01751 319×367 (395 ×695×2.176)\n",
      "18 Shrimp 0.08759124088 0.02021 249×318 (186 ×95×0.987)\n",
      "19 Waffle 0.01034482759 0.01902 294×338 (465 ×537×0.8)\n",
      "20 Pizza 0.01034482759 0.01913 292×336 (442 ×651×1.176)\n",
      "After finding keyframes, PixSfM estimated the poses and point cloud. After generating scaled meshes,\n",
      "the team calculated volumes and Chamfer distance with and without transformation metrics. Meshes\n",
      "were registered with ground truth meshes using ICP to obtain transformation metrics.\n",
      "Table 3 presents quantitative comparisons of the team’s volumes and Chamfer distance with and\n",
      "without estimated transformation metrics from ICP. For overall method performance, Table 4 shows\n",
      "the MAPE and Chamfer distance with and without transformation metrics.\n",
      "Additionally, qualitative results on one- and few-shot 3D reconstruction from the challenge dataset\n",
      "are shown. The model excels in texture details, artifact correction, missing data handling, and color\n",
      "adjustment across different scene parts.\n",
      "Limitations: Despite promising results, several limitations need to be addressed in future work:\n",
      "•Manual processes: The current pipeline includes manual steps like providing segmentation\n",
      "prompts and identifying scaling factors, which should be automated to enhance efficiency.\n",
      "•Input requirements: The method requires extensive input information, including food\n",
      "masks and depth data. Streamlining these inputs would simplify the process and increase\n",
      "applicability.\n",
      "•Complex backgrounds and objects: The method has not been tested in environments with\n",
      "complex backgrounds or highly intricate food objects.\n",
      "•Capturing complexities: The method has not been evaluated under different capturing\n",
      "complexities, such as varying distances and camera speeds.\n",
      "•Pipeline complexity: For one-shot neural rendering, the team currently uses One-2-3-45.\n",
      "They aim to use only the 2D diffusion model, Zero123, to reduce complexity and improve\n",
      "efficiency.\n",
      "6Table 3: Quantitative Comparison with Ground Truth Using Chamfer Distance\n",
      "L Id Team’s V ol. GT V ol. Ch. w/ t.m Ch. w/o t.m\n",
      "1 40.06 38.53 1.63 85.40\n",
      "2 216.9 280.36 7.12 111.47\n",
      "3 278.86 249.67 13.69 172.88\n",
      "E 4 279.02 295.13 2.03 61.30\n",
      "5 395.76 392.58 13.67 102.14\n",
      "6 205.17 218.44 6.68 150.78\n",
      "7 372.93 368.77 4.70 66.91\n",
      "8 186.62 173.13 2.98 152.34\n",
      "9 224.08 232.74 3.91 160.07\n",
      "10 153.76 163.09 2.67 138.45\n",
      "M 11 80.4 85.18 3.37 151.14\n",
      "13 363.99 308.28 5.18 147.53\n",
      "14 535.44 589.83 4.31 89.66\n",
      "16 163.13 262.15 18.06 28.33\n",
      "H 17 224.08 181.36 9.44 28.94\n",
      "18 25.4 20.58 4.28 12.84\n",
      "19 110.05 108.35 11.34 23.98\n",
      "20 130.96 119.83 15.59 31.05\n",
      "Table 4: Quantitative Comparison with Ground Truth Using MAPE and Chamfer Distance\n",
      "MAPE Ch. w/ t.m Ch. w/o t.m\n",
      "(%) sum mean sum mean\n",
      "10.973 0.130 0.007 1.715 0.095\n",
      "5 Second Place Team - ININ-VIAUN\n",
      "5.1 Methodology\n",
      "This section details the team’s proposed network, illustrating the step-by-step process from original\n",
      "images to final mesh models.\n",
      "5.1.1 Scale factor estimation\n",
      "The procedure for estimating the scale factor at the coordinate level is illustrated in Figure 9. The\n",
      "team adheres to a method involving corner projection matching. Specifically, utilizing the COLMAP\n",
      "dense model, the team acquires the pose of each image along with dense point cloud data. For any\n",
      "given image imgkand its extrinsic parameters [R|t]k, the team initially performs threshold-based\n",
      "corner detection, setting the threshold at 240. This step allows them to obtain the pixel coordinates\n",
      "of all detected corners. Subsequently, using the intrinsic parameters kand the extrinsic parameters\n",
      "[R|t]k, the point cloud is projected onto the image plane. Based on the pixel coordinates of the\n",
      "corners, the team can identify the closest point coordinates Pk\n",
      "ifor each corner, where irepresents the\n",
      "index of the corner. Thus, they can calculate the distance between any two corners as follows:\n",
      "Dk\n",
      "ij= (Pk\n",
      "i−Pk\n",
      "j)2∀i̸=j (3)\n",
      "To determine the final computed length of each checkerboard square in image k, the team takes the\n",
      "minimum value of each row of the matrix Dk(excluding the diagonal) to form the vector dk. The\n",
      "median of this vector is then used. The final scale calculation formula is given by Equation 4, where\n",
      "0.012 represents the known length of each square (1.2 cm):\n",
      "scale =0.012Pn\n",
      "i=1med(dk)(4)\n",
      "75.1.2 3D Reconstruction\n",
      "The 3D reconstruction process, depicted in Figure 10, involves two different pipelines to accommodate\n",
      "variations in input viewpoints. The first fifteen objects are processed using one pipeline, while the\n",
      "last five single-view objects are processed using another.\n",
      "For the initial fifteen objects, the team uses COLMAP to estimate poses and segment the food using\n",
      "the provided segment masks. Advanced multi-view 3D reconstruction methods are then applied to\n",
      "reconstruct the segmented food. The team employs three different reconstruction methods: COLMAP,\n",
      "DiffusioNeRF, and NeRF2Mesh. They select the best reconstruction results from these methods and\n",
      "extract the mesh. The extracted mesh is scaled using the estimated scale factor, and optimization\n",
      "techniques are applied to obtain a refined mesh.\n",
      "For the last five single-view objects, the team experiments with several single-view reconstruction\n",
      "methods, including Zero123, Zero123++, One2345, ZeroNVS, and DreamGaussian. They choose\n",
      "ZeroNVS to obtain a 3D food model consistent with the distribution of the input image. The\n",
      "intrinsic camera parameters from the fifteenth object are used, and an optimization method based\n",
      "on reprojection error refines the extrinsic parameters of the single camera. Due to limitations in\n",
      "single-view reconstruction, depth information from the dataset and the checkerboard in the monocular\n",
      "image are used to determine the size of the extracted mesh. Finally, optimization techniques are\n",
      "applied to obtain a refined mesh.\n",
      "5.1.3 Mesh refinement\n",
      "During the 3D Reconstruction phase, it was observed that the model’s results often suffered from low\n",
      "quality due to holes on the object’s surface and substantial noise, as shown in Figure 11.\n",
      "To address the holes, MeshFix, an optimization method based on computational geometry, is em-\n",
      "ployed. For surface noise, Laplacian Smoothing is used for mesh smoothing operations. The\n",
      "Laplacian Smoothing method adjusts the position of each vertex to the average of its neighboring\n",
      "vertices:\n",
      "V(new)\n",
      "i =V(old)\n",
      "i+λ\n",
      "1\n",
      "|N(i)|X\n",
      "j∈N(i)V(old)\n",
      "j−V(old)\n",
      "i\n",
      " (5)\n",
      "In their implementation, the smoothing factor λis set to 0.2, and 10 iterations are performed.\n",
      "5.2 Experimental Results\n",
      "5.2.1 Estimated scale factor\n",
      "The scale factors estimated using the described method are shown in Table 5. Each image and the\n",
      "corresponding reconstructed 3D model yield a scale factor, and the table presents the average scale\n",
      "factor for each object.\n",
      "5.2.2 Reconstructed meshes\n",
      "The refined meshes obtained using the described methods are shown in Figure 12. The predicted\n",
      "model volumes, ground truth model volumes, and the percentage errors between them are presented\n",
      "in Table 6.\n",
      "5.2.3 Alignment\n",
      "The team designs a multi-stage alignment method for evaluating reconstruction quality. Figure 13\n",
      "illustrates the alignment process for Object 14. First, the central points of both the predicted and\n",
      "ground truth models are calculated, and the predicted model is moved to align with the central point\n",
      "of the ground truth model. Next, ICP registration is performed for further alignment, significantly\n",
      "reducing the Chamfer distance. Finally, gradient descent is used for additional fine-tuning to obtain\n",
      "the final transformation matrix.\n",
      "The total Chamfer distance between all 18 predicted models and the ground truths is 0.069441169.\n",
      "8Table 5: Estimated Scale Factors\n",
      "Object Index Food Item Scale Factor\n",
      "1 Strawberry 0.060058\n",
      "2 Cinnamon bun 0.081829\n",
      "3 Pork rib 0.073861\n",
      "4 Corn 0.083594\n",
      "5 French toast 0.078632\n",
      "6 Sandwich 0.088368\n",
      "7 Burger 0.103124\n",
      "8 Cake 0.068496\n",
      "9 Blueberry muffin 0.059292\n",
      "10 Banana 0.058236\n",
      "11 Salmon 0.083821\n",
      "13 Burrito 0.069663\n",
      "14 Hotdog 0.073766\n",
      "Table 6: Metric of V olume\n",
      "Object Index Predicted V olume Ground Truth Error Percentage\n",
      "1 44.51 38.53 15.52\n",
      "2 321.26 280.36 14.59\n",
      "3 336.11 249.67 34.62\n",
      "4 347.54 295.13 17.76\n",
      "5 389.28 392.58 0.84\n",
      "6 197.82 218.44 9.44\n",
      "7 412.52 368.77 11.86\n",
      "8 181.21 173.13 4.67\n",
      "9 233.79 232.74 0.45\n",
      "10 160.06 163.09 1.86\n",
      "11 86.0 85.18 0.96\n",
      "13 334.7 308.28 8.57\n",
      "14 517.75 589.83 12.22\n",
      "16 176.24 262.15 32.77\n",
      "17 180.68 181.36 0.37\n",
      "18 13.58 20.58 34.01\n",
      "19 117.72 108.35 8.64\n",
      "20 117.43 119.83 20.03\n",
      "6 Best 3D Mesh Reconstruction Team - FoodRiddle\n",
      "6.1 Methodology\n",
      "To achieve high-fidelity food mesh reconstruction, the team developed two procedural pipelines as\n",
      "depicted in Figure 14. For simple and medium complexity cases, they employed a structure-from-\n",
      "motion strategy to ascertain the pose of each image, followed by mesh reconstruction. Subsequently,\n",
      "a sequence of post-processing steps was implemented to recalibrate the scale and improve mesh\n",
      "quality. For cases involving only a single image, the team utilized image generation techniques to\n",
      "facilitate model generation.\n",
      "6.1.1 Multi-View Reconstruction\n",
      "For Structure from Motion (SfM), the team enhanced the advanced COLMAP method by integrating\n",
      "SuperPoint and SuperGlue techniques. This integration significantly addressed the issue of limited\n",
      "keypoints in scenes with minimal texture, as illustrated in Figure 15.\n",
      "In the mesh reconstruction phase, the team’s approach builds upon 2D Gaussian Splatting, which\n",
      "employs a differentiable 2D Gaussian renderer and includes regularization terms for depth distortion\n",
      "9and normal consistency. The Truncated Signed Distance Function (TSDF) results are utilized to\n",
      "produce a dense point cloud.\n",
      "During post-processing, the team applied filtering and outlier removal methods, identified the outline\n",
      "of the supporting surface, and projected the lower mesh vertices onto this surface. They utilized\n",
      "the reconstructed checkerboard to correct the model’s scale and employed Poisson reconstruction to\n",
      "create a complete, watertight mesh of the subject.\n",
      "6.1.2 Single-View Reconstruction\n",
      "For 3D reconstruction from a single image, the team utilized advanced methods such as LGM, Instant\n",
      "Mesh, and One-2-3-45 to generate an initial mesh. This initial mesh was then refined in conjunction\n",
      "with depth structure information.\n",
      "To adjust the scale, the team estimated the object’s length using the checkerboard as a reference,\n",
      "assuming that the object and the checkerboard are on the same plane. They then projected the 3D\n",
      "object back onto the original 2D image to obtain a more precise scale for the object.\n",
      "6.2 Experimental Results\n",
      "Through a process of nonlinear optimization, the team sought to identify a transformation that\n",
      "minimizes the Chamfer distance between their mesh and the ground truth mesh. This optimization\n",
      "aimed to align the two meshes as closely as possible in three-dimensional space. Upon completion\n",
      "of this process, the average Chamfer dis- tance across the final reconstructions of the 20 objects\n",
      "amounted to 0.0032175 meters. As shown in Table 7, Team FoodRiddle achieved the best scores for\n",
      "both multi- view and single-view reconstructions, outperforming other teams in the competition.\n",
      "Table 7: Total Errors for Different Teams on Multi-view and Single-view Data\n",
      "Team Multi-view (1-14) Single-view (16-20)\n",
      "FoodRiddle 0.036362 0.019232\n",
      "ININ-VIAUN 0.041552 0.027889\n",
      "V olETA 0.071921 0.058726\n",
      "7 Conclusion\n",
      "This report examines and compiles the techniques and findings from the MetaFood Workshop\n",
      "challenge on 3D Food Reconstruction. The challenge sought to enhance 3D reconstruction methods\n",
      "by concentrating on food items, tackling the distinct difficulties presented by varied textures, reflective\n",
      "surfaces, and intricate geometries common in culinary subjects.\n",
      "The competition involved 20 diverse food items, captured under various conditions and with differing\n",
      "numbers of input images, specifically designed to challenge participants in creating robust reconstruc-\n",
      "tion models. The evaluation was based on a two-phase process, assessing both portion size accuracy\n",
      "through Mean Absolute Percentage Error (MAPE) and shape accuracy using the Chamfer distance\n",
      "metric.\n",
      "Of all participating teams, three reached the final submission stage, presenting a range of innovative\n",
      "solutions. Team V olETA secured first place with the best overall performance in both Phase-I and\n",
      "Phase-II, followed by team ININ-VIAUN in second place. Additionally, the FoodRiddle team\n",
      "exhibited superior performance in Phase-II, highlighting a competitive and high-caliber field of\n",
      "entries for 3D mesh reconstruction. The challenge has successfully advanced the field of 3D food\n",
      "reconstruction, demonstrating the potential for accurate volume estimation and shape reconstruction\n",
      "in nutritional analysis and food presentation applications. The novel methods developed by the\n",
      "participating teams establish a strong foundation for future research in this area, potentially leading\n",
      "to more precise and user-friendly approaches for dietary assessment and monitoring.\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "article = df['PDF'].iloc[0]\n",
    "print(type(article))\n",
    "\n",
    "if pd.isna(article) or not isinstance(article, str) or not article.strip():\n",
    "    print(\"The first entry in the 'PDF' column is invalid or empty.\")\n",
    "else:\n",
    "    print(\"Valid article:\", article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
